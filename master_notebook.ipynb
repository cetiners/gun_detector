{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd092ba50c92c9dc11b366869717e90d544d23b7140e20708921d0ff91f276d2e3f",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils import sorter, cleaner\n",
    "from modules.kerasfns import create_model, model_fitter, pred_perf, hist_acc\n",
    "from modules.preprocess import loader, sample_print\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean & split image data into folders \n",
    "[cleaner(i) for i in [\"train\",\"test\",\"validation\"]]\n",
    "\n",
    "sorter(.6,.2,.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing train / test / valid datasets:\n",
    "\n",
    "train = loader(\"train\",\n",
    "augmentation = True, \n",
    "rotation_range= 45, \n",
    "width_shift_range=.2, \n",
    "height_shift_range=.2, \n",
    "shear_range = 0.2, \n",
    "zoom_range = 0.2, \n",
    "horizontal_flip = True)\n",
    "\n",
    "valid = loader(\"validation\")\n",
    "test_set = loader(\"test\", shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL TRIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial #1 - Creating the base model\n",
    "\n",
    "model1 = create_model([32,64,128], neuron_dense=256, dropout=True)\n",
    "hist1, model1 = model_fitter(model1,10,train,valid)\n",
    "pred1 = pred_perf(model1,test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "# Trial #2 - Dropout - Disharmony!\n",
    "model2 = create_model([32,64,128], neuron_dense=256 )\n",
    "hist2, model2 = model_fitter(model2,10,train,valid)\n",
    "pred2 = pred_perf(model2,test_set)\n",
    "\n",
    "#As several sources and article suggest, using both pooling and dropout may actually cause disharmony between the two, and resulting with a worse model than if neither or just one of them were used. In this particular model the performance is not significantly affected by using/removing Dropout, however, as there is a slight increase in accuaracy and decrease in loss, we decided to remove Dropout.abs\n",
    "\n",
    "# It should also be noted that Dropout layer was tested later on in the projet, this time causing a more significant decrease in model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trial #3 - Increase number of neurons in the Conv layers\n",
    "model3 = create_model([64,128,256], neuron_dense=256)\n",
    "hist3, model3 = model_fitter(model3,10,train,valid)\n",
    "pred3 = pred_perf(model3,test_set)\n",
    "\n",
    "#Increasing number of neurons in the conv layers caused overfitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial #4 - Increase the number of conv layers (to 4)\n",
    "model4 = create_model([32,64,128,128], neuron_dense=256)\n",
    "hist4, model4 = model_fitter(model4,10,train,valid)\n",
    "pred4 = pred_perf(model4,test_set)\n",
    "\n",
    "#Adding hidden layers improved model performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial #5 - Increase the number of conv layers (to 5)\n",
    "model5 = create_model([32,64,128,128,128], neuron_dense=256)\n",
    "hist5, model5 = model_fitter(model5,10,train,valid)\n",
    "pred5 = pred_perf(model5,test_set)\n",
    "\n",
    "# Adding another hidden layer did not improve the model performance, and although the model is able to reach %84 val_acc in around 5 epochs, model then overfits and not able to improve val_acc anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial #6 - Set number of neurons in the Dense layer (to 128)\n",
    "model6 = create_model([32,64,128,128])\n",
    "hist6, model6 = model_fitter(model6,10,train,valid)\n",
    "pred6 = pred_perf(model6,test_set)\n",
    "\n",
    "# After several examples and research on the subject, equalling the number of neurons in the last convolution layer and the dense layer seems to be a common concept in CNNs. Therefore, the neuron number in the Dense layer was set to 128 which actually did improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial #7 - Adding kernel_initializer\n",
    "model7 = create_model([32,64,128,128], kernel_initializer='he_uniform')\n",
    "hist7, model7 = model_fitter(model7,10,train,valid)\n",
    "pred7 = pred_perf(model7,test_set)\n",
    "\n",
    "# Using he_uniform or he_normal as the kernel_initializers actually improved model performance slightly. Howeever, it seems changing between the two does not have a significant difference for this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trial #8 - Padding\n",
    "model8 = create_model([32,64,128,128], kernel_initializer='he_uniform', padding=\"same\")\n",
    "hist8, model8 = model_fitter(model8,10,train,valid)\n",
    "pred8 = pred_perf(model8,test_set)\n",
    "\n",
    "# Changing padding from \"valid\" to \"same\" improved model performance as we were able to retain original image size, which would otherwise be decreased during the convolution operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial #9 - Adding kernel_regularizer\n",
    "model9 = create_model([32,64,128,128], kernel_initializer='he_uniform', kernel_regularizer=l2(0.01), padding=\"same\")\n",
    "hist9, model9 = model_fitter(model9,20,train,valid)\n",
    "pred9 = pred_perf(model9,test_set)\n",
    "\n",
    "#Adding kernel regularizer actually decreased the model performance, with validation accuracy never even reaching 80% during 20 epochs. Therefore, this parameter will not be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With the parameter tuning the overall performance has improved and is now able to give out >80% validation accuracy over multiple trials with 10+ epochs. Therefore, we can now use callbacks to train the model longer (larger epochs) and save the best one to be submitted.\n",
    "\n",
    "#Preparing Callbacks\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "mc = ModelCheckpoint('best_model.hdf5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trial #10 - Trying out the best model yet with 50 epochs\n",
    "model10 = create_model([32,64,128,128], kernel_initializer='he_uniform', padding=\"same\")\n",
    "hist10, model10 = model_fitter(model10,50,train,valid, callbacks=[es,mc])\n",
    "pred10 = pred_perf(model10,test_set)\n",
    "\n",
    "# The iteration stops around 20-30 epochs due to early stopping callback, however the model performance seems encouraging as we are able to reach around 88% val_acc, the highest number yet! To view the overall process we can use hist_acc fundtion to plot the loss and accuracy metrics across epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_acc(hist10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a final test we can reload the model and evaluate it again to test the performance of our final model one last time.\n",
    "\n",
    "model_final = load_model(\"/Saved Models/best_model.hdf5\")\n",
    "pred_final = pred_perf(final_model)\n",
    "\n",
    "# The predictions have a loss of 0.3382 and an accuracy of 0.8480\n",
    "# By evaluating these values, we decided to use this model as the final product of this project, and can be used for threat level detection."
   ]
  }
 ]
}